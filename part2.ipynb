{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da152d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4187b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft2(x):  return torch.fft.fft2(x, dim=(-2, -1))\n",
    "def ifft2(x): return torch.fft.ifft2(x, dim=(-2, -1))\n",
    "\n",
    "def project_unit_magnitude(s, eps=1e-8):\n",
    "    S = fft2(s)\n",
    "    S = S / (torch.abs(S) + eps)\n",
    "    return ifft2(S).real\n",
    "\n",
    "def sample_secret_like(x):\n",
    "    s = torch.randn_like(x)\n",
    "    return project_unit_magnitude(s)\n",
    "\n",
    "def hrr_bind(x, s):\n",
    "    # x âŠ› s = F^{-1}(F(x) * F(s))\n",
    "    return ifft2(fft2(x) * fft2(s)).real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c8007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "full_train = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "\n",
    "target_train, target_test, population_data = random_split(full_train, [20000, 20000, 10000])\n",
    "\n",
    "train_loader = DataLoader(target_train, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cifar_resnet18():\n",
    "    m = resnet18(num_classes=10)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48560cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HRR target model...\n",
      "epoch 1/5 done\n",
      "epoch 2/5 done\n",
      "epoch 3/5 done\n",
      "epoch 4/5 done\n",
      "epoch 5/5 done\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def train_hrr_model(loader, epochs=5, lr=1e-3):\n",
    "    model = make_cifar_resnet18().to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            s = sample_secret_like(x)      # (B,C,H,W)\n",
    "            x_enc = hrr_bind(x, s)         # (B,C,H,W)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            out = model(x_enc)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        print(f\"epoch {ep+1}/{epochs} done\")\n",
    "    return model\n",
    "\n",
    "print(\"Training HRR target model...\")\n",
    "target_model = train_hrr_model(train_loader, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRRWrapper(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base = base_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = sample_secret_like(x)\n",
    "        x_enc = hrr_bind(x, s)\n",
    "        return self.base(x_enc)\n",
    "\n",
    "def get_rmia_score_multi(tar_model, ref_models, known_img, known_label, population_subset, gamma=1.0, a=0.3):\n",
    "    tar_model.eval()\n",
    "    for rm in ref_models: rm.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob_x_target = torch.softmax(tar_model(known_img.unsqueeze(0)), dim=1)[0, known_label].item()\n",
    "        all_ref_probs_x = [\n",
    "            torch.softmax(rm(known_img.unsqueeze(0)), dim=1)[0, known_label].item()\n",
    "            for rm in ref_models\n",
    "        ]\n",
    "        prob_x_out = float(np.mean(all_ref_probs_x))\n",
    "\n",
    "        pr_x = 0.5 * ((1 + a) * prob_x_out + (1 - a))\n",
    "        ratio_x = prob_x_target / (pr_x + 1e-10)\n",
    "\n",
    "        count = 0\n",
    "        for z_img, z_label in population_subset:\n",
    "            prob_z_target = torch.softmax(tar_model(z_img.unsqueeze(0)), dim=1)[0, z_label].item()\n",
    "            all_ref_probs_z = [\n",
    "                torch.softmax(rm(z_img.unsqueeze(0)), dim=1)[0, z_label].item()\n",
    "                for rm in ref_models\n",
    "            ]\n",
    "            prob_z_out = float(np.mean(all_ref_probs_z))\n",
    "            ratio_z = prob_z_target / (prob_z_out + 1e-10)\n",
    "\n",
    "            if (ratio_x / (ratio_z + 1e-10)) > gamma:\n",
    "                count += 1\n",
    "\n",
    "    return count / len(population_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4814f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HRR reference models...\n",
      "epoch 1/5 done\n",
      "epoch 2/5 done\n",
      "epoch 3/5 done\n",
      "epoch 4/5 done\n",
      "epoch 5/5 done\n",
      "epoch 1/5 done\n",
      "epoch 2/5 done\n",
      "epoch 3/5 done\n",
      "epoch 4/5 done\n",
      "epoch 5/5 done\n"
     ]
    }
   ],
   "source": [
    "num_ref_models = 2\n",
    "ref_models = []\n",
    "\n",
    "pop_indices = np.arange(len(population_data))\n",
    "\n",
    "print(\"Training HRR reference models...\")\n",
    "for i in range(num_ref_models):\n",
    "    np.random.shuffle(pop_indices)\n",
    "    subset = Subset(population_data, pop_indices[:len(pop_indices)//2])\n",
    "    loader = DataLoader(subset, batch_size=64, shuffle=True)\n",
    "\n",
    "    m = train_hrr_model(loader, epochs=5)\n",
    "    ref_models.append(m)\n",
    "\n",
    "target_wrapped = HRRWrapper(target_model).to(device)\n",
    "refs_wrapped = [HRRWrapper(m).to(device) for m in ref_models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8b1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRR + RMIA AUROC: 0.5021\n"
     ]
    }
   ],
   "source": [
    "z_samples = [population_data[i] for i in range(100)]\n",
    "\n",
    "scores, labels = [], []\n",
    "\n",
    "for i in range(100):\n",
    "    img_m, lbl_m = target_train[i]\n",
    "    img_n, lbl_n = target_test[i]\n",
    "\n",
    "    img_m, img_n = img_m.to(device), img_n.to(device)\n",
    "\n",
    "    scores.append(get_rmia_score_multi(target_wrapped, refs_wrapped, img_m, lbl_m, z_samples))\n",
    "    labels.append(1)\n",
    "\n",
    "    scores.append(get_rmia_score_multi(target_wrapped, refs_wrapped, img_n, lbl_n, z_samples))\n",
    "    labels.append(0)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels, scores)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "print(f\"HRR + RMIA AUROC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb5637e",
   "metadata": {},
   "source": [
    "The RMIA attack was evaluated against the HRR-protected model.\n",
    "The attack achieved an AUROC of 0.5021, which is approximately equal to random guessing (0.5).\n",
    "This indicates that the HRR defense effectively prevents the attack from distinguishing between training members and non-members."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
