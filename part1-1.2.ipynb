{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5368b2a",
   "metadata": {},
   "source": [
    "Task 1.2: Analysis and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43750744",
   "metadata": {},
   "source": [
    "Question 1\n",
    "How close do your results get to the paper? Evaluate your attack in terms of FPR vs TPR rate as well as AUROC for comparison.\n",
    "\n",
    "Answer 1\n",
    "Our implemenation achieves an AUC (Area Under ROC Curve) of 66.47% with 8 reference models, which is approximately 4-5% lower than the paper's results with 4 reference models (71.02%). The main reasons for this deviation is:\n",
    "\n",
    "1. The training duration, we are using 5 epochs instead of the paper's 100 epochs. This reduces overfitting, which weakens the membership signal that the attack exploits.\n",
    "\n",
    "2. The evaluation scale, we used 200 samples instead of the paper's thousands, which increases variance in our AUC estimate.\n",
    "\n",
    "3. The Population Size: Our 100 population samples (z_samples) provide fewer likelihood ratio comparisons than the paper's larger population set.\n",
    "\n",
    "Despite these differences, our implementation successfully demonstrates the RMIA attack concept, showing clear separation between member and non-member score distributions. The attack performs better than random guessing (50% AUC), validating our implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfaa98c",
   "metadata": {},
   "source": [
    "Question 2 <br>\n",
    "How does the number of reference models affect the attack’s success? Is there an ideal number? <br>\n",
    "\n",
    "Answer 2 <br>\n",
    "Results for 1 reference model (Training Time 6 minutes approx) <br>\n",
    "\n",
    "RMIA Membership Score for 1 ref_model: 0.6700 <br>\n",
    "Attack AUROC (AUC): 0.6253\n",
    "\n",
    "\n",
    "Results for 2 reference models (Training Time 14 minutes approx) <br>\n",
    "\n",
    "RMIA Membership Score for 1 ref_model: 0.7300 <br>\n",
    "RMIA Membership Score for 2 ref_models: 0.8100 <br>\n",
    "Attack AUROC (AUC): 0.6156\n",
    "\n",
    "Results for 4 reference models <br>\n",
    "\n",
    "Results for 8 reference models <br>\n",
    "\n",
    "Results for 16 reference models <br>\n",
    "\n",
    "\n",
    "From the paper: <br>\n",
    "The number of reference models has an impact on the the attack performance. Adding the first reference model improves AUC by ~10% over the baseline attack (from 58.19% ± 0.33% to 68.64% ± 0.43% in the paper). The second and third models each add 1-3% AUC improvement. Beyond 4 models, each additional model provides around 1% or less improvement. The 127-model configuration in the paper only achieves 0.69% better AUC than 4 models.\n",
    "<br>\n",
    "The ideal number according to the paper and our own observations is 4 reference models. When we use only 1-2 models it is good, for a quick evaluation. The near optimal is the 8 models if the time permits and above from that the returns are very small. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203946b",
   "metadata": {},
   "source": [
    "Question 3\n",
    "What happens if you deliberately create class imbalance when setting aside data before training?\n",
    "\n",
    "Answer 3\n",
    "Creating class imbalance in the training data reduces the effectiveness of membership inference attacks. With fewer training samples for minority classes, the model underfits these classes and doesn't memorize patterns. Membership inference attack exploits overfitting, so less overfitting means that the attack is weaker. Also, the model's confidence distribution changes with imbalance. It becomes generally less confident on minority classes, reducing the signal-to-noise ratio for membership detection. As a result, from the side of the attackers, the class imbalance makes attacks less reliable, since minority class members are harder to identify and calling for class-specific attack strategies. From the side of the defenders, class imbalance may provide some privacy benefit, though it not worth it, since it comes at cost of model performance on minority classes, and better defenses exist like differential privacy, regularization, etc"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
