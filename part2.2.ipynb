{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c70d080",
   "metadata": {},
   "source": [
    "1. How effective is HRR?\n",
    "\n",
    "The HRR defense worked very well.\n",
    "When we ran the RMIA attack on the protected model, the AUROC was 0.5021, which is almost the same as random guessing (0.5).\n",
    "This means the attacker could not tell if a sample was in the training data or not.\n",
    "\n",
    "The reason is that HRR changes every image before the model sees it.\n",
    "Because of this, the attacker can no longer use the modelâ€™s confidence to detect membership.\n",
    "So the attack basically stops working.\n",
    "\n",
    "2. Is HRR encryption?\n",
    "\n",
    "HRR is not real encryption.\n",
    "It does not fully protect the data like encryption does.\n",
    "Instead, it just changes the image using a secret so it becomes hard to understand.\n",
    "\n",
    "The model can still use the image because it was trained that way, but an attacker cannot easily understand it.\n",
    "So HRR is more like hiding or scrambling the data, not encrypting it.\n",
    "\n",
    "3. Can an attacker still break it?\n",
    "\n",
    "Yes, a strong attacker could still try to break this defense.\n",
    "\n",
    "For example, if the attacker somehow gets the secret that is used in HRR, they could apply the same transformation and attack the model again.\n",
    "\n",
    "The attacker could also send the same input many times and average the outputs to reduce the randomness.\n",
    "\n",
    "So HRR makes the attack much harder, but it is not a perfect defense."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
